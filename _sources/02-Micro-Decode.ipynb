{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2. Upstream analysis \n",
    "- (From raw sequencing data to Feature counts matrix and Pathway counts matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.1 Basic Pipeline\n",
    "\n",
    "This chapter aims to guide you through the general pipeline of 16S analysis.\n",
    "\n",
    "QIIME2 has provided a quite user-friendly documents, check:\n",
    "- https://docs.qiime2.org/2024.10/tutorials/overview/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Note}\n",
    "The tutorial's command will depends on version: qiime2-2023.2. The code might be changed slightly when you use different version of QIIME2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Upstream: Importing data amd Examine the quality\n",
    "\n",
    "Import your sequencing data using `qiime tools import`. I hope you have already noticed that we should use `manifest` to input multiple sequencing data into qiime2.\n",
    "- Select the correct input type based on the tutorial. Check [here](https://docs.qiime2.org/2024.10/tutorials/importing/#fastq-manifest-formats).\n",
    "- Mind that your sample id or name should be the same as that in sample metadata (mentioned in chapter 1). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```shell\n",
    "qiime tools import   --type 'SampleData[PairedEndSequencesWithQuality]' \\\n",
    "  --input-path manifest.tsv  \\\n",
    "  --output-path paired-end-demux.qza  \\\n",
    "  --input-format PairedEndFastqManifestPhred33V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Tip}\n",
    "* check the example of the **manifest** and **sample-metadata** from *NEEN* project in the link [here](https://github.com/nedchen2/DecodingMicrobiota/tree/main/document/QIIME2_manifest)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After importation, Examine the sequencing quality `Interactive Quality Plot` with `qiime demux summarize`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "# make a report to judge the base length to trim\n",
    "qiime demux summarize --i-data paired-end-demux.qza --o-visualization paired-end-demux.qzv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Upstream: Adapter/Primer/Barcodes trimming\n",
    "\n",
    "The artificial sequence (Adapter/Primer/Barcodes) will significantly influence the results of the classifiers, therefore it is essential to check and trim the sequence. We will apply cutadapt's QIIM2 plugin for this purpose.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "qiime cutadapt trim-paired \\                  # again, if you are single end data, change the command\n",
    "    --p-cores 4 \\\n",
    "    --i-demultiplexed-sequences paired-end-demux.qza \\\n",
    "    --p-front-f GTGCCAGCMGCCGCGGTAA \\         # refers to the primer sequence of forward\n",
    "    --p-front-r GGACTACNNGGGTATCTAAT \\        # refers to the primer sequence of reverse\n",
    "    --p-error-rate 0.1 \\                      # We only 0.1 rate of error\n",
    "    --p-overlap 3 \\\n",
    "    --p-match-read-wildcards \\\n",
    "    --p-match-adapter-wildcards \\             \n",
    "    --p-discard-untrimmed \\                   # If no primer detected, meanings there might be some errors\n",
    "    --o-trimmed-sequences Primer_trimmed-seqs.qza\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The barcode will also be trimed, as long as the primer was detected. Check the trimmed clean data again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check the quality again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "# make a report to judge the base length to trim\n",
    "qiime demux summarize --i-data Primer_trimmed-seqs.qza --o-visualization Primer_trimmed-seqs.qzv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This summary offers visual insights into the distribution of sequence qualities at each position within the sequence data for the subsequent step in the pipeline. The sequence qualities guide decisions regarding certain sequence-processing parameters, including the truncation settings for the DADA2 denoising step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Upstream: Denoise sequences, selecting sequence variants\n",
    "\n",
    "QIIME2 provided two different types of denoising strategy: ASVs and OTUs. Check chapter 3 if you interested in this strategy. `DADA2` is generally suggested for ASVs denosing, while QIIME2 also provides `debular` for the same purpose. You can search for the comparison's between these two tools.\n",
    "\n",
    "Through `qiime dada2 denoise-xx`, we can use dada2 within the QIIME2 platform (xx depends whether your input file is paired-end or single-end).\n",
    "\n",
    "This command enables us to eliminate low-quality regions from the sequences. It also facilitates the removal of primers prior to denoising. DADA2 necessitates the removal of primers to avoid false positive detection of chimeras due to primer degeneracy. \n",
    "\n",
    "Important parameter:\n",
    "\n",
    ">--p-trunc-len-f  : n truncates each forward read sequence at position n\n",
    "\n",
    ">--p-trunc-len-r  : n truncates each reverse read sequence at position n\n",
    "\n",
    ">--p-trim-left-f  : m trims off the first m bases of each forward read sequence\n",
    "\n",
    ">--p-trim-left-r  : m trims off the first m bases of each reverse read sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Click [demux.qzv](https://view.qiime2.org/visualization/?src=https://docs.qiime2.org/2024.10/data/tutorials/moving-pictures-usage/demux.qzv) for an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Question\n",
    ":class: tip\n",
    "* Based on the plots you see in demux.qzv, what values would you choose for `--p-trunc-len` and `--p-trim-left` in this case?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Answer\n",
    ":class: tip, dropdown\n",
    "In this example, we see that the quality of the initial bases seems to be high, so we won’t trim any bases from the beginning of the sequences. The quality seems to drop off around position 120, so we’ll truncate our sequences at 120 bases.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the result from last step to set the parameter used in this step. \n",
    "- \"TBD\": To be determined by your own results. In NEEN project, we set \"TBD\" as zero, as the quality of the sequence was generally good.\n",
    "- Mind that you can also trim the primer sequence through `--p-trim-left`. But it is not generally recommanded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "```shell\n",
    "qiime dada2 denoise-paired \\\n",
    "    --i-demultiplexed-seqs Primer_trimmed-seqs.qza \\\n",
    "    --p-trunc-len-f \"TBD\" \\\n",
    "    --p-trunc-len-r \"TBD\" \\\n",
    "    --p-trim-left-f \"TBD\" \\\n",
    "    --p-trim-left-r \"TBD\" \\\n",
    "    --p-n-threads 4 \\\n",
    "    --o-representative-sequences rep-seqs.qza \\\n",
    "    --o-table table.qza \\\n",
    "    --o-denoising-stats denoising-stats.qza # --o referes to output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After the output, you will get the feature table (ASVs table) and their corresponding sequence (.fasta). But it has also been compacted in the QIIME2 (.qza). \n",
    "\n",
    "Try use `qiime tools peek`\n",
    "- The feature_table.qza is a `FeatureTable[Frequency]` QIIME 2 artifact that contains counts (frequencies) of each\n",
    "unique sequence in each sample in the dataset.\n",
    "- The sequence.qza is a `FeatureData[Sequence]` QIIME 2 artifact, which maps feature identifiers in the\n",
    "FeatureTable to the sequences they represent.\n",
    "\n",
    "Try use `qiime feature-table summarize`\n",
    "- You can also mapping the feature's sequence to NCBI database BLAST through `feature-table tabulate-seqs`. Have a try on the example [here](https://view.qiime2.org/visualization/?src=https://docs.qiime2.org/2024.10/data/tutorials/moving-pictures-usage/rep-seqs.qzv)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Upstream: Building Phylogenetic Tree\n",
    "\n",
    "We can build the phylogenetic tree based on the sequence difference among features. Phylogenetic diversity metrics like Faith's pd, weighted and unweighted Unifrac distance require the phylogenetic tree to calculate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```shell\n",
    "qiime phylogeny align-to-tree-mafft-fasttree \\\n",
    "--i-sequences rep-seqs.qza \\ \n",
    "--o-alignment aligned-rep-seqs.qza \\\n",
    "--o-masked-alignment masked-aligned-rep-seqs.qza \\\n",
    "--o-tree unrooted-tree.qza \\\n",
    "--o-rooted-tree rooted-tree.qza # rep-seqs.qza is sequence of the feature (ASVs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Upstream: Taxonomic assignment\n",
    "\n",
    "ASVs can be used to estimate the community diversity, while, to gain more biological insights, we should be more interested in what species or genus are presented in our data. So, to do this kind of taxonomic assignment, we should have a (1) a reference database, (2) an algorithm that we used to classify our sequence based on reference database.\n",
    "\n",
    "SILVA and greengene2 was the main database used in 16S.\n",
    "\n",
    "In QIIME2, we have different types of pre-trained `naive-bayes` classifiers (click [here](https://docs.qiime2.org/2024.10/data-resources/) ). Those classifiers were mainly trained with (1) full-length of 16S region. (2) V4 region of 16S. \n",
    "- As discussed before, the choice of region to amplify will influence the resolution of your taxonomic assignment. The use of classifiers trained with different region of sequence will also influence the resolution. The more specific, the better.\n",
    "\n",
    "As NEEN project target the v4 region, therefore, we just use the pre-trained v4 region of greengene2 database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```shell\n",
    "qiime feature-classifier classify-sklearn \\\n",
    "--i-classifier classifier.qza \\ \n",
    "--i-reads rep-seqs.qza \\           # sequence of the feature (ASVs)\n",
    "--o-classification taxonomy.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Note}\n",
    "You can also train your own classifiers using `qiime feature-classifier fit-classifier-naive-bayes`. You may find more about how to train your own classifiers, [here](https://github.com/nedchen2/DecodingMicrobiota/blob/main/code/bs.train_classifier.sh). This is the code that I wrote for another project of V3-V4 REGION using SILVA 138.1 database. It will mainly depends on qiime2 plug-in `rescript `. Check [here](https://forum.qiime2.org/t/processing-filtering-and-evaluating-the-silva-database-and-other-reference-sequence-data-with-rescript/15494) for the official documents from the developer.\n",
    "\n",
    "The developers of greengene2 also claimed in this [website](https://forum.qiime2.org/t/introducing-greengenes2-2022-10/25291) that using the `de novo phylogeny` algorithm will have higher resolution in species level. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More\n",
    "\n",
    "Check the official [\"Moving pictures tutorial\"](https://docs.qiime2.org/2024.10/tutorials/moving-pictures-usage/#introduction). Read From \"Sequence quality control and feature table construction\" to the end. You may find that QIIME2 could also be used to do alpha and beta diversity. However, I would still suggest to use R to do the downstream analysis including alpha and beta diversity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Note}\n",
    "Check Points (End of the week)\n",
    "- Import?\n",
    "- Feature Table?\n",
    "- Taxonomic bar chart?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Functional esimation based on PICRUST2\n",
    "\n",
    "This chapter will introduce how can we use PICRUST2 to do functional estimation based on KEGG and Metacyc pathway.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Prepare for the PICRUST2: Installation\n",
    "\n",
    "The installation will vary depends on your computer systems. Check:\n",
    "- You can download picrust2 as the plugin of QIIME2: [here](https://github.com/picrust/picrust2/wiki/q2-picrust2-Tutorial)\n",
    "- Or download picrust2 as a standalone version: [here](https://github.com/picrust/picrust2/wiki/Installation)\n",
    "\n",
    "Or you can directly use Galaxy for graphical interface, which is a web-based platform for accessible, reproducible, and scalable biomedical data analyses (free).\n",
    "- https://usegalaxy.eu/?tool_id=toolshed.g2.bx.psu.edu%2Frepos%2Fiuc%2Fpicrust2_pipeline%2Fpicrust2_pipeline%2F2.5.1%20galaxy0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 PICRUST2 full pipeline\n",
    "\n",
    "To use Galaxy platform for picrust2 standalone version to do prediction, you need to input \n",
    "- the feature-table.biom (a file format used to store ASV table in QIIME2)\n",
    "- dna-sequences.fasta (a fasta file indicating the sequence of different feature you extracted from previous steps), \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "While for QIIME2 plugin, it can directly input the \n",
    "- Feature table QIIME2 artifact (table.qza -  ASV count table )\n",
    "- Feature sequence QIIME2 artifact (rep-seqs.qza - ASV representative sequences)\n",
    "\n",
    "To get the dna-sequences.fasta AND feature-table.biom from the QIIME2 artifact\n",
    "- You can use `qiime tools export`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Note}\n",
    "\n",
    "This turtorial provided code for picrust2 version v2.5.2 or v2.5.3. The developer of picrust2 recently post an update of their software to 2.6.1 \n",
    "check [here](https://github.com/picrust/picrust2/wiki/PICRUSt2%E2%80%90MPGA-database)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "picrust2_pipeline.py -s dna-sequences.fasta \\   #input fasta \n",
    "-i feature-table.biom \\       # input feature table\n",
    "-o picrust2_out_pipeline \\    # output to the directed directory\n",
    "-p 6 --stratified --remove_intermediate --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "check the tutorial here: \n",
    "https://github.com/picrust/picrust2/wiki/Full-pipeline-script\n",
    "\n",
    "The key output files are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{tab-set}\n",
    "```{tab-item} EC_metagenome_out\n",
    "Folder containing unstratified EC number metagenome predictions (pred_metagenome_unstrat.tsv.gz), sequence table normalized by predicted 16S copy number abundances (seqtab_norm.tsv.gz), and the per-sample NSTI values weighted by the abundance of each ASV (weighted_nsti.tsv.gz).\n",
    "```\n",
    "\n",
    "```{tab-item} KO_metagenome_out\n",
    "As EC_metagenome_out above, but for KO metagenomes.\n",
    "```\n",
    "\n",
    "```{tab-item} pathways_out\n",
    "Folder containing predicted pathway abundances and coverages per-sample, based on predicted EC number abundances.\n",
    "```\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Add description\n",
    "\n",
    "Also, they only output the pathway ID and gene ID. You can find the description file which describing the ID, normally under where you installed picrust2: picrust2/default_files/description_mapfiles/.\n",
    "\n",
    "Or use `add_descriptions.py` from picrust2 to do this mission: https://github.com/picrust/picrust2/wiki/Add-descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 KEGG pathway estimation\n",
    "\n",
    "To estimate the KEGG pathway abundance from the KO_metagenome_out, we need to rerun the script using the mapfile from KEGG pathway to KO, like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "```shell\n",
    "pathway_pipeline.py -i picrust2_out_pipeline/KO_metagenome_out/pred_metagenome_contrib.tsv.gz \\ \n",
    "    -o KEGG_pathways_out --no_regroup \\\n",
    "--map KEGG_pathways_to_KO.tsv  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map file has been deposited [here](https://github.com/nedchen2/DecodingMicrobiota/tree/main/document/KEGGdb). Right click to Copy the link to [gitzip](https://kinolien.github.io/gitzip/) and download it. \n",
    "- Please note that this mapfile was created through KEGG database, assessed from 2023-09-26."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{margin} Note\n",
    "- No need to input `Github API Access Token`! Make sure there is nothing present in `Github API Access Token`!!! After you remove everything from the `Github API Access Token`, close the drop-down bar!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./graphics/Gitzip.png\" alt=\"gitzip.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Key limitations of PICRUST2\n",
    "\n",
    "Read Key limitations [here](https://github.com/picrust/picrust2/wiki/Key-Limitations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{Note}\n",
    "Check Points (End of the week)\n",
    "- PATHWAY TABLE?\n",
    "- Description?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Analysis Platform: Galaxy\n",
    "\n",
    "Here, we offer some possible trouble shootings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trouble Shooting for Galaxy\n",
    "\n",
    "<u>1.Import your data into the Galaxy.</u>\n",
    "\n",
    "- Dataset expects a single file containing the data, where as a collection like you are trying to upload is a directory(folder) of data. \n",
    "\n",
    "\n",
    "Currently, we do not have a good instructions for data importing, but what I am pretty sure is you can not use `manifest` to input your data. \n",
    "\n",
    "- Possibility 1 (rule-based builder)\n",
    "\n",
    "Put your data online first, and then follow the instructions in the link [here](https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/020-tutorial-upstream/030-importing.html), \n",
    "And check: the rule builder will be your friend at the moment:\n",
    "\n",
    "Hands-on: [Rule Based Uploader / Rule Based Uploader / Using Galaxy and Managing your Data](https://training.galaxyproject.org/training-material/topics/galaxy-interface/tutorials/upload-rules/tutorial.html)\n",
    "\n",
    "Hands-on: [Rule Based Uploader: Advanced / Rule Based Uploader: Advanced / Using Galaxy and Managing your Data](https://training.galaxyproject.org/training-material/topics/galaxy-interface/tutorials/upload-rules-advanced/tutorial.html)\n",
    "\n",
    "- Possibility 2 (Collection builder)\n",
    "\n",
    "First your file should follow the naming format of `Casava One Eight Single Lane Per Sample Directory Format`, match the following regex: `.+_.+_R[12]_001.fastq.gz`. Example like: `FMT.0093C_46_L001_R2_001.fastq.gz`.\n",
    "\n",
    "Click `Upload Data`, select `Collection`, if paired-end data change Collection Type to List of Pairs, and add the local or ftp files. Click Start, and then Build.\n",
    "\n",
    "- Possibility 3 (Local machine builder)\n",
    "\n",
    "Otherwise, we would still suggest to use local computer with manifest to import the raw data into `.qza` and then upload it.\n",
    "\n",
    "Find more:\n",
    "- https://docs.qiime2.org/jupyterbooks/cancer-microbiome-intervention-tutorial/020-tutorial-upstream/030-importing.html\n",
    "- https://usegalaxy.no/static/userguide/uploadfiles.html\n",
    "- https://forum.qiime2.org/t/using-qiime2-in-galaxy/27232/5\n",
    "- https://forum.qiime2.org/t/import-failure-with-the-public-galaxy/26362/11\n",
    "\n",
    "<u>2.I do not know how to cut the adapter from the single end sequence.</u>\n",
    "\n",
    "- https://forum.qiime2.org/t/cut-adapt-for-single-end-sequences/18648\n",
    "\n",
    "\n",
    "<u>3.Can not find input `biom` for picrust2 after using `qiime2 export`.</u>\n",
    "\n",
    "There is a mismatch between the biom file name from the newest version of qiime2 (BIOMv2DirFmt) and picrust2.5.3 (BIOMv2). You can first download your exported biom file. And then upload it again to the Galaxy. Galaxy will auto detect the format which would be acceptable for picurst2. \n",
    "\n",
    "<u>4.Can not find the input KO_metagenome_out/pred_metagenome_contrib.tsv.gz in Galaxy after finish picrust2 `full pipeline` ?</u>\n",
    "\n",
    "Use the `...` (Browse and upload your datasets) to find the hidden layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Sequencing Platform: Pacbio CCS - Full length 16S\n",
    "\n",
    "We will provide some trouble shooting here\n",
    "\n",
    "## Trouble Shooting for Pacbio CCS\n",
    "\n",
    "<u>1, Do not know how to input?</u>\n",
    "\n",
    "For those users sequenced with Pacbio CCS platform, you could import your reads as single end. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "qiime tools import\n",
    "--type 'SampleData[SequencesWithQuality]'\n",
    "--input-path se-33-manifest\n",
    "--output-path single-end-demux.qza\n",
    "--input-format SingleEndFastqManifestPhred33V2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<u>2.How to denoise, do we need to cut adapter/primer before denoising?</u>\n",
    "\n",
    "No, you do not need to cut adapter/primer before denoising.\n",
    "\n",
    "Denoise your reads with `qiime dada2 denoise-ccs`, because the command use Pacbio error model, which is different from previous next generation sequencing platform, to denoise. \n",
    "\n",
    "You should set the primer information to the command, otherwise the software can not find the target to denoise, and it will cut the adapter for you: \n",
    "\n",
    "`--p-front`  : Forward primer in 5' to 3'. Example: 27F/1492R - AGAGTTTGATCMTGGCTCAG\n",
    "\n",
    "`--p-adapter`: Reverse primer in 5' to 3'. Example: 27F/1492R - TACGGYTACCTTGTTAYGACTT\n",
    "\n",
    "Check the [link](https://docs.qiime2.org/2024.10/plugins/available/dada2/denoise-ccs/). And the author has shown their github [here](https://github.com/benjjneb/LRASManuscript) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please also noted that if you still can not get a satisfactory retained reads. It may mean that some of the sequencing providers do not provide a sequence with adequate quality. In that casem we may transfer to OTU clustering with `--p-perc-identity 0.99`. Also, you need to remove the primer and re-orient the ccs reads using `dada2::removePrimers` in R first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Downstream analysis: Suggestions for beginners\n",
    "\n",
    "Check:\n",
    "- see [qiime2R](https://forum.qiime2.org/t/tutorial-integrating-qiime2-and-r-for-data-visualization-and-analysis-using-qiime2r/4121) to input the qiime2 artifacts to phyloseq\n",
    "- see my tutorial (Chapter 3) for basic analysis using phyloseq\n",
    "- [MicrobiotaProcess](https://bioconductor.org/packages/release/bioc/vignettes/MicrobiotaProcess/inst/doc//MicrobiotaProcess.html#anatomy-of-a-mpse) - Easy to use and impressive visualization.  \n",
    "- [microeco](https://chiliubio.github.io/microeco_tutorial/) - For a better visualization and comprehensive microbial community analysis.\n",
    "\n",
    "Metabolomics and integration\n",
    "- MetaboanalystR (https://www.metaboanalyst.ca/docs/RTutorial.xhtml)\n",
    "- Pathway analysis\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{glossary}\n",
    "ASVs\n",
    "    Amplicon Sequence Variants (ASVs) \n",
    "\n",
    "Map file\n",
    "    In bioinformatics, we mainly called some files could be used to represent some relationships between objects as map files.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "447.67px",
    "left": "33.6667px",
    "top": "422px",
    "width": "310.288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
